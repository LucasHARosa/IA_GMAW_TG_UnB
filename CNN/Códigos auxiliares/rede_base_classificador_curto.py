# -*- coding: utf-8 -*-
"""Classificador_curto1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dFtmyo6jeKHPFc1ID02Gk7uSpPldeByk

# Classificação de momentos de curto

Criação da primeira rede neural convolucional do projeto, para testes 


- Base de 1000 imagens experimento 1
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.layers.normalization.batch_normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

trainDf = pd.read_excel("/content/drive/MyDrive/TCC/Treino.xlsx")
testeDf = pd.read_excel("/content/drive/MyDrive/TCC/Treino.xlsx")
colTrain = "Curto"
#print(trainDf.dtypes)
trainDf["Curto"] = trainDf["Curto"].astype(str)
testeDf["Curto"] = testeDf["Curto"].astype(str)
#print(trainDf.dtypes)

datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.1)

train_generator = datagen.flow_from_dataframe(
    dataframe=trainDf,
    directory='/content/drive/MyDrive/TCC/Experimentos',
    x_col='Imagem',
    y_col= "Curto",
    subset='training',  # Conjunto de treinamento
    batch_size=20,
    color_mode='grayscale',
    class_mode='binary',  # Para classificação binária
    target_size=(230, 230)  # Tamanho desejado das imagens
)

validation_generator = datagen.flow_from_dataframe(
    dataframe=trainDf,
    directory='/content/drive/MyDrive/TCC/Experimentos',
    x_col='Imagem',
    y_col= "Curto",
    subset='validation',  # Conjunto de validação
    batch_size=20,
    color_mode='grayscale',
    class_mode='binary',
    target_size=(230, 230)
)

model = Sequential()
model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(230, 230, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(30, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(30, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(30, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(30, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))  # Saída para regressão

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=validation_generator
)

print(history)

train_loss = history.history['binary_accuracy']
val_loss = history.history['val_binary_accuracy']

train_metric = history.history['metric']
val_metric = history.history['val_metric']

# Plotar o gráfico de função de erro
plt.plot(train_loss, label='Train binary accuracy')
plt.plot(val_loss, label='Validation binary accuracy')
plt.title('Acurácia')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.show()

# Plotar o gráfico da métrica
plt.plot(train_metric, label='Train Metric')
plt.plot(val_metric, label='Validation Metric')
plt.title('Métrica')
plt.xlabel('Épocas')
plt.ylabel('Metric')
plt.legend()
plt.show()

h = history.history

print(val_loss)

evaluation_results = model.evaluate_generator(generator=validation_generator)

# Imprima as métricas de desempenho
print("Loss: ", evaluation_results[0])
print("Accuracy: ", evaluation_results[1])